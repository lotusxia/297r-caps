{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model description \n",
    "\n",
    "Two versions of models:\n",
    "\n",
    "1. Target Variable: \n",
    "    - change in monthly BSR\n",
    "   Feature Variable:\n",
    "    - word count of reviews in the previous month\n",
    "    \n",
    "2. Target Variable:\n",
    "    - monthly BSR\n",
    "   Feature Variables:\n",
    "    - word count of reviews in *all* reviews in and before the previous month\n",
    "    \n",
    "    \n",
    "In either case, \n",
    "\n",
    "- use a Bag of Word (TF-IDF) model on the 500 most common tri-grams/bi-grams from the training set.\n",
    "- run LASSO/Ridge using the 500 features\n",
    "\n",
    "    \n",
    "Training set:\n",
    "\n",
    "    - 2836 products (1/3 of all products in the dataset)\n",
    "    - 68559 month-product pairs\n",
    "    \n",
    "Testing set:\n",
    "\n",
    "    - 945 products (1/3 of the size of training set)\n",
    "    - 24340 month-product pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1429,
     "status": "ok",
     "timestamp": 1646364394745,
     "user": {
      "displayName": "Lotus Xia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03620880809577638378"
     },
     "user_tz": 300
    },
    "id": "YS8LWmA4GDK6"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_session=boto3.session=boto3.Session(\n",
    "    aws_access_key_id='AKIAQF74TYKWB5URILW2',\n",
    "    aws_secret_access_key='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')\n",
    "s3_client= current_session.client('s3')\n",
    "\n",
    "def download_object(file_path_on_s3_bucket, path_to_file_on_local, bucket_name=\"ac297r\", s3_client=s3_client):\n",
    "    with open(path_to_file_on_local, 'wb') as f:\n",
    "        s3_client.download_fileobj(bucket_name, file_path_on_s3_bucket, f)\n",
    "    return True\n",
    "\n",
    "def upload_object(file_path_on_s3_bucket, path_to_file_on_local, bucket_name=\"ac297r\", s3_client=s3_client):\n",
    "    s3_client.upload_file(path_to_file_on_local, bucket_name, file_path_on_s3_bucket)\n",
    "    return True\n",
    "\n",
    "def get_object(file_path_on_s3_bucket, bucket_name=\"ac297r\", s3_client=s3_client):\n",
    "    return s3_client.get_object(Bucket=bucket_name, Key=file_path_on_s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1646364395450,
     "user": {
      "displayName": "Lotus Xia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03620880809577638378"
     },
     "user_tz": 300
    },
    "id": "f5nT-9MeM_YY",
    "outputId": "10b38f11-fb75-48bc-b709-4f94aa8e51a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_object('clean/month_level_rank.pickle', \n",
    "                '/home/ubuntu/data/month_level_rank.pickle', bucket_name='ac297r', s3_client=s3_client)\n",
    "download_object('clean/month_level_review.pickle', \n",
    "                '/home/ubuntu/data/month_level_review.pickle', bucket_name='ac297r', s3_client=s3_client)\n",
    "download_object('clean/product_sample.pickle', \n",
    "                '/home/ubuntu/data/product_sample.pickle', bucket_name='ac297r', s3_client=s3_client)\n",
    "download_object('raw/rank_sales.csv', \n",
    "                '/home/ubuntu/data/rank_sales.csv', bucket_name='ac297r', s3_client=s3_client)\n",
    "download_object('raw/rank_sales.csv', \n",
    "                '/home/ubuntu/data/rank_sales.csv', bucket_name='ac297r', s3_client=s3_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1646364395608,
     "user": {
      "displayName": "Lotus Xia",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03620880809577638378"
     },
     "user_tz": 300
    },
    "id": "XH3TZRA0NEAJ"
   },
   "outputs": [],
   "source": [
    "# input folders\n",
    "data = \"/home/ubuntu/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_pickle(f'{data}/month_level_review.pickle')\n",
    "sample_prod = pd.read_pickle(f'{data}/product_sample.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (108375, 3)\n"
     ]
    }
   ],
   "source": [
    "train_prod = sample_prod['train']\n",
    "test_prod = sample_prod['test']\n",
    "rev = review.query('asin in @train_prod | asin in @test_prod').copy().reset_index(drop=True)\n",
    "rev = rev[['asin', 'year_month', 'review_text']].copy()\n",
    "print('size:', rev.shape)\n",
    "del sample_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all reviews in a prod-month into a big blob of text\n",
    "rev['review_text'] = rev['review_text'].str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>year_month</th>\n",
       "      <th>median_month_rank</th>\n",
       "      <th>median_month_rank_prev</th>\n",
       "      <th>median_month_rank_diff</th>\n",
       "      <th>predict_using_year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000052XB5</td>\n",
       "      <td>07-2017</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000052XB5</td>\n",
       "      <td>08-2017</td>\n",
       "      <td>0.088999</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>-0.001909</td>\n",
       "      <td>07-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000052XB5</td>\n",
       "      <td>09-2017</td>\n",
       "      <td>0.087918</td>\n",
       "      <td>0.088999</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>08-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000052XB5</td>\n",
       "      <td>10-2017</td>\n",
       "      <td>0.050594</td>\n",
       "      <td>0.087918</td>\n",
       "      <td>-0.037324</td>\n",
       "      <td>09-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000052XB5</td>\n",
       "      <td>11-2017</td>\n",
       "      <td>0.052829</td>\n",
       "      <td>0.050594</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>10-2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323776</th>\n",
       "      <td>B08QBXMHRT</td>\n",
       "      <td>03-2021</td>\n",
       "      <td>0.046404</td>\n",
       "      <td>0.183434</td>\n",
       "      <td>-0.137030</td>\n",
       "      <td>02-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323777</th>\n",
       "      <td>B08QBXMHRT</td>\n",
       "      <td>04-2021</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0.046404</td>\n",
       "      <td>-0.032643</td>\n",
       "      <td>03-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323778</th>\n",
       "      <td>B08QBXMHRT</td>\n",
       "      <td>05-2021</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>04-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323779</th>\n",
       "      <td>B08QBXMHRT</td>\n",
       "      <td>06-2021</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>-0.005661</td>\n",
       "      <td>05-2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323780</th>\n",
       "      <td>B08QBXMHRT</td>\n",
       "      <td>07-2021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>06-2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322539 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin year_month  median_month_rank  median_month_rank_prev  \\\n",
       "0       B000052XB5    07-2017           0.090908                     NaN   \n",
       "1       B000052XB5    08-2017           0.088999                0.090908   \n",
       "2       B000052XB5    09-2017           0.087918                0.088999   \n",
       "3       B000052XB5    10-2017           0.050594                0.087918   \n",
       "4       B000052XB5    11-2017           0.052829                0.050594   \n",
       "...            ...        ...                ...                     ...   \n",
       "323776  B08QBXMHRT    03-2021           0.046404                0.183434   \n",
       "323777  B08QBXMHRT    04-2021           0.013760                0.046404   \n",
       "323778  B08QBXMHRT    05-2021           0.027598                0.013760   \n",
       "323779  B08QBXMHRT    06-2021           0.021938                0.027598   \n",
       "323780  B08QBXMHRT    07-2021           0.000000                0.021938   \n",
       "\n",
       "        median_month_rank_diff predict_using_year_month  \n",
       "0                          NaN                      NaN  \n",
       "1                    -0.001909                  07-2017  \n",
       "2                    -0.001081                  08-2017  \n",
       "3                    -0.037324                  09-2017  \n",
       "4                     0.002235                  10-2017  \n",
       "...                        ...                      ...  \n",
       "323776               -0.137030                  02-2021  \n",
       "323777               -0.032643                  03-2021  \n",
       "323778                0.013838                  04-2021  \n",
       "323779               -0.005661                  05-2021  \n",
       "323780               -0.021938                  06-2021  \n",
       "\n",
       "[322539 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the rank data\n",
    "bsr = pd.read_pickle(f'{data}/month_level_rank.pickle')[['asin', 'year_month', 'median_month_rank']]\n",
    "bsr['median_month_rank_prev'] = bsr.groupby(['asin'])['median_month_rank'].shift(1)\n",
    "bsr['median_month_rank_diff'] = bsr['median_month_rank'] - bsr['median_month_rank_prev']\n",
    "bsr['predict_using_year_month'] = bsr.groupby(['asin'])['year_month'].shift(1)\n",
    "bsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge rank and text\n",
    "df = bsr[['asin', 'predict_using_year_month', 'median_month_rank', 'median_month_rank_diff']].merge(rev, how='inner', \n",
    "                                               left_on=['asin', 'predict_using_year_month'], \n",
    "                                               right_on=['asin', 'year_month']).drop('predict_using_year_month', \n",
    "                                                                                     axis=1)\n",
    "del bsr, rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into train and test\n",
    "train_df = df.query('asin in @train_prod')\n",
    "test_df = df.query('asin in @test_prod')\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>median_month_rank</th>\n",
       "      <th>median_month_rank_diff</th>\n",
       "      <th>year_month</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00005313T</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>07-2017</td>\n",
       "      <td>Bought this for my brother...and he seems like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00005313T</td>\n",
       "      <td>0.015020</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>08-2017</td>\n",
       "      <td>Years ago my GP recommended this particular vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00005313T</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>09-2017</td>\n",
       "      <td>I ned a multi with no iron and this does the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00005313T</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>10-2017</td>\n",
       "      <td>Contains potentially dangerous levels of B6 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00005313T</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>11-2017</td>\n",
       "      <td>Great Excellent. If you cant afford Dualtabs, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  median_month_rank  median_month_rank_diff year_month  \\\n",
       "0  B00005313T           0.005682                0.005682    07-2017   \n",
       "1  B00005313T           0.015020                0.009337    08-2017   \n",
       "2  B00005313T           0.015266                0.000247    09-2017   \n",
       "3  B00005313T           0.020440                0.005173    10-2017   \n",
       "4  B00005313T           0.027367                0.006927    11-2017   \n",
       "\n",
       "                                         review_text  \n",
       "0  Bought this for my brother...and he seems like...  \n",
       "1  Years ago my GP recommended this particular vi...  \n",
       "2  I ned a multi with no iron and this does the t...  \n",
       "3  Contains potentially dangerous levels of B6 an...  \n",
       "4  Great Excellent. If you cant afford Dualtabs, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_vectorizer(vectorizer, train_df, test_df, target, cumulative=False):\n",
    "\n",
    "    vectorizer.fit(train_df['review_text'])\n",
    "    vocab = vectorizer.get_feature_names_out() # get vocab\n",
    "    \n",
    "    # transform training/test reviews\n",
    "    X_train = vectorizer.transform(train_df['review_text'])\n",
    "    X_test = vectorizer.transform(test_df['review_text'])\n",
    "    y_train = train_df[target]\n",
    "    y_test = test_df[target]\n",
    "    \n",
    "    # if we want to compute cumulative mean\n",
    "    if cumulative: \n",
    "        \n",
    "        print('''Compute cumulative mean:''')\n",
    "        \n",
    "        # X_train \n",
    "        vocab_df = pd.DataFrame(X_train.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "        X_train = pd.concat([train_df['asin'].reset_index(drop=True), \n",
    "                              vocab_df.reset_index()], axis=1)\n",
    "\n",
    "        X_train['n_days'] = X_train.groupby('asin')['asin'].cumcount() + 1\n",
    "        for word in vocab:\n",
    "            X_train[word] = X_train.groupby('asin')[word].cumsum()\n",
    "            X_train[word] = X_train[word]/X_train['n_days']\n",
    "\n",
    "        X_train = scipy.sparse.csr_matrix(X_train[vocab].values) # get back to sparse matrix\n",
    "        \n",
    "        # X_test\n",
    "        vocab_df = pd.DataFrame(X_test.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "        X_test = pd.concat([test_df['asin'].reset_index(drop=True), \n",
    "                              vocab_df.reset_index()], axis=1)\n",
    "\n",
    "        X_test['n_days'] = X_test.groupby('asin')['asin'].cumcount() + 1\n",
    "        for word in vocab:\n",
    "            X_test[word] = X_test.groupby('asin')[word].cumsum()\n",
    "            X_test[word] = X_test[word]/X_test['n_days']\n",
    "\n",
    "        X_test = scipy.sparse.csr_matrix(X_test[vocab].values) # get back to sparse matrix\n",
    "\n",
    "    print('training size:', X_train.shape)\n",
    "    print('testing size:', X_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, vocab\n",
    "\n",
    "# LASSO\n",
    "def run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True):\n",
    "    alphas = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "    r2_list = []\n",
    "    \n",
    "    print('''\n",
    "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "    ''')\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        clf = linear_model.Lasso(alpha=alpha, max_iter=100000)\n",
    "        clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "        r2 = clf.score(X=X_test, y=y_test)\n",
    "        r2_list.append(r2)\n",
    "        print(alpha, '\\t', r2)\n",
    "\n",
    "    print('-------------------------')\n",
    "    best_alpha = alphas[np.argmax(np.array(r2_list))]\n",
    "    print('best alpha', best_alpha)\n",
    "    clf = linear_model.Lasso(alpha=alpha, max_iter=100000)\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    if print_words:\n",
    "        print('good words:')\n",
    "        print(get_words(clf, words='best', n_words = 10))\n",
    "\n",
    "        print('bad words:')\n",
    "        print(get_words(clf, words='worst', n_words = 10))\n",
    "    \n",
    "    return clf\n",
    "    \n",
    "    \n",
    "def run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True):\n",
    "    \n",
    "    alphas = [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "    r2_list = []\n",
    "    \n",
    "    print('''\n",
    "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
    "    ''')\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        clf = linear_model.Ridge(alpha=alpha, max_iter=100000)\n",
    "        clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "        r2 = clf.score(X=X_test, y=y_test)\n",
    "        r2_list.append(r2)\n",
    "        print(alpha, '\\t', r2)\n",
    "\n",
    "    print('-------------------------')\n",
    "    best_alpha = alphas[np.argmax(np.array(r2_list))]\n",
    "    print('best alpha', best_alpha)\n",
    "    clf = linear_model.Ridge(alpha=alpha, max_iter=100000)\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    if print_words:\n",
    "        print('good words:')\n",
    "        print(get_words(clf, words='best', n_words = 10))\n",
    "\n",
    "        print('bad words:')\n",
    "        print(get_words(clf, words='worst', n_words = 10))\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def get_words(trained_model, words='best', n_words = 10):\n",
    "    if words == 'best':\n",
    "        good_words = vocab[trained_model.coef_ > 0] \n",
    "        pos_coef = trained_model.coef_[trained_model.coef_ > 0]\n",
    "        best_words = good_words[np.argsort(-pos_coef)][:n_words]\n",
    "        return best_words\n",
    "    elif words == 'worst':\n",
    "        bad_words = vocab[trained_model.coef_ < 0] \n",
    "        neg_coef = trained_model.coef_[trained_model.coef_ < 0]\n",
    "        worst_words = bad_words[np.argsort(neg_coef)][:n_words]\n",
    "        return worst_words\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Monthly Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (Tri-gram) Monthly Reviews to Predict Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -3.8135903040137364e-05\n",
      "0.1 \t -3.8135903040137364e-05\n",
      "0.01 \t -3.8135903040137364e-05\n",
      "0.001 \t -3.8135903040137364e-05\n",
      "0.0001 \t 9.968012484473654e-05\n",
      "-------------------------\n",
      "best alpha 0.0001\n",
      "good words:\n",
      "['product did work' 'great product really' 'makes feel good'\n",
      " 'don waste money' 'feel better taking' 'love product great'\n",
      " 'increase milk supply' 'great product fast' 'gummies taste great'\n",
      " 've using product']\n",
      "bad words:\n",
      "['horny goat weed' 'hair skin nails' 'capsules easy swallow'\n",
      " 'apple cider vinegar' 'omega fish oil']\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.009061896933330482\n",
      "0.1 \t -0.009092307271288291\n",
      "0.01 \t -0.009098775122230673\n",
      "0.001 \t -0.009099452904677507\n",
      "0.0001 \t -0.009099742915217535\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['makes feel good' 'great product fast' 've using week'\n",
      " 'time swallowing pills' 'highly recommend trying' 'product did work'\n",
      " 'feel like helping' 'lower blood sugar' 'best ve tried' 'help joint pain']\n",
      "bad words:\n",
      "['product definitely recommend' 'started taking weeks'\n",
      " 'notice huge difference' 'product feel better' 'trouble swallowing pills'\n",
      " 'makes feel great' 'day highly recommend' 've using months'\n",
      " 'product fast delivery' 'just ordered second']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(3,3), stop_words='english', max_features = 500)\n",
    "\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank_diff', cumulative=False)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# run ridge regression \n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Tri-gram) Monthly Review to Predict Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -3.8135903040137364e-05\n",
      "0.1 \t -3.8135903040137364e-05\n",
      "0.01 \t -3.8135903040137364e-05\n",
      "0.001 \t -3.8135903040137364e-05\n",
      "0.0001 \t -3.8135903040137364e-05\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "[]\n",
      "bad words:\n",
      "[]\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.007615621226081615\n",
      "0.1 \t -0.007770046991758317\n",
      "0.01 \t -0.007805721201099569\n",
      "0.001 \t -0.007809308086804023\n",
      "0.0001 \t -0.007809666971462681\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['great product fast' 'scoop coffee morning' 'tell huge difference'\n",
      " 've using week' 'difference skin hair' 'brain octane oil'\n",
      " 'feel like helping' 'product did work' 'super easy swallow'\n",
      " 'day great product']\n",
      "bad words:\n",
      "['far great product' 'product fast delivery' 'like maple syrup'\n",
      " 'product definitely recommend' 'day highly recommend'\n",
      " 'just ordered second' 'plan continue using' 'love product really'\n",
      " 'love great product' 'makes feel great']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3), stop_words='english', max_features = 500)\n",
    "\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank_diff', cumulative=False)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# ridge regression\n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (Bi-gram) Monthly Reviews to Predict Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -3.8135903040137364e-05\n",
      "0.1 \t -3.8135903040137364e-05\n",
      "0.01 \t -3.8135903040137364e-05\n",
      "0.001 \t 3.322045441145338e-05\n",
      "0.0001 \t -0.0010862679736725056\n",
      "-------------------------\n",
      "best alpha 0.001\n",
      "good words:\n",
      "['changed life' 'great flavor' 'looks like' 'hard swallow' 'did work'\n",
      " 'really bad' 'works great' 'product ve' 'just ordered' 'acid reflux']\n",
      "bad words:\n",
      "['product buy' 'energy boost' 'stuff works' 'taking probiotics' 'don need'\n",
      " 'pleasantly surprised' 'urinary tract' 'amazing product' 'happy purchase'\n",
      " 'difference energy']\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.008090672923934505\n",
      "0.1 \t -0.008095853638971473\n",
      "0.01 \t -0.00809719024355493\n",
      "0.001 \t -0.008096276127890434\n",
      "0.0001 \t -0.008102003654164136\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['changed life' 'looks like' 'great flavor' 'product doesn' 'just ordered'\n",
      " 'weeks noticed' 'satisfied product' 'really bad' 'seeing results'\n",
      " 'great good']\n",
      "bad words:\n",
      "['product buy' 'stuff works' 'don need' 'pleasantly surprised'\n",
      " 'product recommend' 'times week' 'love vitamins' 'taking probiotics'\n",
      " 'really feel' 'energy boost']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2), stop_words='english', max_features = 500)\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank_diff', cumulative=False)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# ridge regression\n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Bi-gram) Monthly Reviews to Predict Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -3.8135903040137364e-05\n",
      "0.1 \t -3.8135903040137364e-05\n",
      "0.01 \t -3.8135903040137364e-05\n",
      "0.001 \t -3.8135903040137364e-05\n",
      "0.0001 \t 1.1366950833147094e-05\n",
      "-------------------------\n",
      "best alpha 0.0001\n",
      "good words:\n",
      "['works great' 'easy swallow' 'good product' 'great price' 'great product']\n",
      "bad words:\n",
      "[]\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.004203763710061148\n",
      "0.1 \t -0.0042823548994910254\n",
      "0.01 \t -0.004300498826595778\n",
      "0.001 \t -0.004302319315065306\n",
      "0.0001 \t -0.0043025024328700034\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['cider vinegar' 'changed life' 'great good' 'began taking' 'free bottle'\n",
      " 'super easy' 'seeing results' 'looks like' 'read reviews' 'really bad']\n",
      "bad words:\n",
      "['days feel' 'apple cider' 'loved product' 'taking probiotics'\n",
      " 'pleasantly surprised' 'like energy' 'swallow good' 'product continue'\n",
      " 'taking weeks' 'glass water']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2), stop_words='english', max_features = 500)\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank_diff', cumulative=False)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# ridge regression\n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cumulative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (Tri-gram) Cumulative Reviews to Predict Monthly Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute cumulative mean:\n",
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.0014111716562019705\n",
      "0.1 \t -0.0014111716562019705\n",
      "0.01 \t -0.0014111716562019705\n",
      "0.001 \t 0.0014565364632549427\n",
      "0.0001 \t 0.004652895452083916\n",
      "-------------------------\n",
      "best alpha 0.0001\n",
      "good words:\n",
      "['gummies taste great' 'cod liver oil' 've using months'\n",
      " 'using product years' 'great product helps' 'omega fish oil'\n",
      " 'low carb diet' 'lost 10 pounds' 'taking product months'\n",
      " 'swallow easy swallow']\n",
      "bad words:\n",
      "['good price good' 'year old loves' 'taste really good'\n",
      " 'great product definitely' 'product good product' 'good product works'\n",
      " 'great product fast' 'good value money' 'drink plenty water'\n",
      " 'hard time swallowing']\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.05068311652960067\n",
      "0.1 \t -0.05364920200316914\n",
      "0.01 \t -0.054495339060786074\n",
      "0.001 \t -0.054575408763182676\n",
      "0.0001 \t -0.05457840286050741\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['feel great taking' 'swallow easy swallow' 'lost 10 lbs'\n",
      " 'really does help' 'great product highly' 'feel like helped'\n",
      " 'recommend great product' 'difference right away' 'easy swallow ve'\n",
      " 've using week']\n",
      "bad words:\n",
      "['day easy swallow' 'big easy swallow' 'recommend giving try'\n",
      " 'good product works' 'good value price' 'great product fast'\n",
      " 'continue taking product' 'good price good' 've noticed difference'\n",
      " 'days taking product']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(3,3), stop_words='english', max_features = 500)\n",
    "\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank', cumulative=True)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# run ridge regression \n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Tri-gram) Cumulative Review to Predict Monthly Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute cumulative mean:\n",
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.0014111716562019705\n",
      "0.1 \t -0.0014111716562019705\n",
      "0.01 \t -0.0014111716562019705\n",
      "0.001 \t -0.0014111716562019705\n",
      "0.0001 \t 0.004357645532868881\n",
      "-------------------------\n",
      "best alpha 0.0001\n",
      "good words:\n",
      "['cod liver oil']\n",
      "bad words:\n",
      "['year old loves' 'taste really good' 'product great product'\n",
      " 'good price good' 'easy swallow taste' 'taste like candy'\n",
      " 'just started using' 'definitely recommend product'\n",
      " 'noticed increase energy' 'great product great']\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.017195329081929778\n",
      "0.1 \t -0.02305854104229721\n",
      "0.01 \t -0.02474910883816106\n",
      "0.001 \t -0.024927540652847746\n",
      "0.0001 \t -0.024945490665843284\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['feel great taking' 'swallow easy swallow' 'super easy swallow'\n",
      " 'great product highly' 'hair nails grow' 'started taking weeks'\n",
      " 'omega fish oil' 'difference skin hair' 'recommend great product'\n",
      " 'recommend product great']\n",
      "bad words:\n",
      "['big easy swallow' 'day easy swallow' 'great product fast'\n",
      " 'recommend product looking' 'good product works' 'good price good'\n",
      " 'make sure drink' 'easy swallow bad' 'great product definitely'\n",
      " 'better highly recommend']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3), stop_words='english', max_features = 500)\n",
    "\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank', cumulative=True)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# ridge regression\n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (Bi-gram) Cumulative Reviews to Predict Monthly Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute cumulative mean:\n",
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.0014111716562019705\n",
      "0.1 \t -0.0014111716562019705\n",
      "0.01 \t 0.0019572586787154345\n",
      "0.001 \t 0.005984637128910397\n",
      "0.0001 \t 0.0010322056244562727\n",
      "-------------------------\n",
      "best alpha 0.001\n",
      "good words:\n",
      "['great flavor' 'free bottle' 'garden life' 'product years'\n",
      " 'gummies taste' 'product highly' 'liked product' 'product really'\n",
      " 'changed life' 'lose weight']\n",
      "bad words:\n",
      "['don want' 'fish burps' 'days taking' 'product just' 'good value'\n",
      " 'using month' 'price good' 'definitely buy' 'don think'\n",
      " 'noticed improvement']\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.0750569762260116\n",
      "0.1 \t -0.07571047405746745\n",
      "0.01 \t -0.07588872189523133\n",
      "0.001 \t -0.07589967594586788\n",
      "0.0001 \t -0.07589694562124016\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['great reviews' 'great flavor' 'didn help' 'day day' 'received product'\n",
      " 'don waste' 'changed life' 'looks like' 'product years' 'using years']\n",
      "bad words:\n",
      "['noticed improvement' 'fish burps' 'satisfied product' 'don want'\n",
      " 'using month' '10 days' 'product doesn' 'works just' 'lost lbs'\n",
      " 'product gives']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2), stop_words='english', max_features = 500)\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank', cumulative=True)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# ridge regression\n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Bi-gram) Cumulative Reviews to Predict Monthly Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute cumulative mean:\n",
      "training size: (68559, 500)\n",
      "testing size: (24340, 500)\n",
      "\n",
      "    Running LASSO regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.0014111716562019705\n",
      "0.1 \t -0.0014111716562019705\n",
      "0.01 \t -0.0014111716562019705\n",
      "0.001 \t -0.0014111716562019705\n",
      "0.0001 \t 0.009898174835077711\n",
      "-------------------------\n",
      "best alpha 0.0001\n",
      "good words:\n",
      "['garden life' 'fish oil' 'excellent product']\n",
      "bad words:\n",
      "['ve noticed' 'far good' 'taste good' 'easy swallow' 'good value'\n",
      " 'taste great' 'great value' 'product just' 'quality product' 'year old']\n",
      "\n",
      "    Running ridge regression with alphas in [0.5, 0.1, 0.01, 0.001, 0.0001]\n",
      "    \n",
      "0.5 \t -0.02202767138989259\n",
      "0.1 \t -0.025882010129543165\n",
      "0.01 \t -0.02692167074808549\n",
      "0.001 \t -0.02703008853661304\n",
      "0.0001 \t -0.02704096895815189\n",
      "-------------------------\n",
      "best alpha 0.5\n",
      "good words:\n",
      "['free bottle' 'purchase product' 'ancestral supplements' 'began taking'\n",
      " 'immune support' 'day day' 'product didn' 'great reviews' 'didn help'\n",
      " 'nails stronger']\n",
      "bad words:\n",
      "['bone marrow' 'noticed improvement' 'swallow great' 'energy focus'\n",
      " 'fish burps' 'haven seen' 'covid 19' 'product amazing' 'like energy'\n",
      " 'definitely buy']\n"
     ]
    }
   ],
   "source": [
    "# define vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2), stop_words='english', max_features = 500)\n",
    "X_train, X_test, y_train, y_test, vocab = bow_vectorizer(vectorizer, train_df, test_df, \n",
    "                                                         target='median_month_rank', cumulative=True)\n",
    "\n",
    "# run lass regression \n",
    "lasso = run_lasso(X_train, y_train, X_test, y_test, vocab, print_words=True)\n",
    "\n",
    "# ridge regression\n",
    "ridge = run_ridge(X_train, y_train, X_test, y_test, vocab, print_words=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNE2/G6OOdOoL5sGCGsqiAC",
   "collapsed_sections": [],
   "name": "regression_w_text_BoW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
